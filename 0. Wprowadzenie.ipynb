{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4824cc0",
   "metadata": {},
   "source": [
    "Przed oddaniem zadania upewnij się, że wszystko działa poprawnie.\n",
    "**Uruchom ponownie kernel** (z paska menu: Kernel$\\rightarrow$Restart) a następnie\n",
    "**wykonaj wszystkie komórki** (z paska menu: Cell$\\rightarrow$Run All).\n",
    "\n",
    "Upewnij się, że wypełniłeś wszystkie pola `TU WPISZ KOD` lub `TU WPISZ ODPOWIEDŹ`, oraz\n",
    "że podałeś swoje imię i nazwisko poniżej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e2d9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72331aed",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41c0314",
   "metadata": {},
   "source": [
    "# 0. Wprowadzenie\n",
    "\n",
    "W trakcie dzisiejszego laboratorium zbadamy różne architektury sieci neuronowych i ich odporność na transformacje (symetrie) danych wejściowych. W tym celu wykorzystamy znane już podejście autokodera, który będzie uczony na zbiorze danych odręcznie pisanych cyfr – MNIST.\n",
    "\n",
    "## 0.1. Zbiór MNIST\n",
    "Przygotowana została klasa `SampledMNISTData`, która pozwoli na używanie: (1) pełnego zbioru (parametr `num_samples_per_class = -1`) lub (2) losowego podzbioru instancji (parametr `num_samples_per_class > 0`).\n",
    "\n",
    "Poniższy fragment kodu wizualizuje losowo wybrane instancje ze zbioru MNIST. Każdy obrazek jest tensorem wymiaru `(1, 28, 28)`, tzn. obrazki są wymiaru 28x28 pikseli oraz są zapisane w skali szarości (1 kanał).\n",
    "\n",
    "## 0.2. Modele\n",
    "\n",
    "Modele oraz zbiór danych zostały zaimplementowane w bibliotece PyTorch, przy czym na etapie uczenia modeli wykorzystany został PyTorch-Lightning, który znacznie upraszcza proces uczenia modeli (wrócimy do tego później).\n",
    "\n",
    "Ze względu czas uczenia poszczególnych modeli oraz ograniczenia czasowe podczas laboratorium, wykorzystywane modele zostały już przeuczone. Kod znajduje się w odpowiednich zeszytach. Właściwa część laboratorium będzie korzystać z tych wyuczonych modeli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e4e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import SampledMNISTData\n",
    "\n",
    "mnist = SampledMNISTData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566854ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def visualize_random_sample(dataset, num_samples: int = 10, seed: int = 42):\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.choice(range(len(dataset)), size=num_samples)\n",
    "    \n",
    "    fig, axs = plt.subplots(ncols=num_samples, figsize=(15, 5))\n",
    "    \n",
    "    axs[0].set(ylabel=\"Original\")\n",
    "    \n",
    "    for i, sample_idx in enumerate(indices):\n",
    "        org_img, label = dataset[sample_idx]\n",
    "        axs[i].imshow(org_img[0], cmap=\"gray\")\n",
    "        axs[i].set(title=f\"Digit: {label}\", xticks=[], yticks=[])\n",
    "            \n",
    "            \n",
    "\n",
    "    \n",
    "visualize_random_sample(dataset=mnist.mnist_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
