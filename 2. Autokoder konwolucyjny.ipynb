{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d33709",
   "metadata": {},
   "source": [
    "Przed oddaniem zadania upewnij się, że wszystko działa poprawnie.\n",
    "**Uruchom ponownie kernel** (z paska menu: Kernel$\\rightarrow$Restart) a następnie\n",
    "**wykonaj wszystkie komórki** (z paska menu: Cell$\\rightarrow$Run All).\n",
    "\n",
    "Upewnij się, że wypełniłeś wszystkie pola `TU WPISZ KOD` lub `TU WPISZ ODPOWIEDŹ`, oraz\n",
    "że podałeś swoje imię i nazwisko poniżej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f121bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0bbc96",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84234e55",
   "metadata": {},
   "source": [
    "# 2. Model konwolucyjny (CNN)\n",
    "Następnie sprawdzimy architekturę autokodera opartego na warstwach konwolucyjnych (CNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9030701f",
   "metadata": {},
   "source": [
    "## 2.1. Architektura\n",
    "Zapoznaj się z poniższymi implementacjami kodera i dekodera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40fc0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Code\n",
    "\n",
    "\n",
    "Code(filename=\"src/cnn.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560a3531",
   "metadata": {},
   "source": [
    "## 2.2. Uczenie modelu\n",
    "Podobnie jak w przypadku poprzedniego przykładu, model został nauczony i załączony w repozytorium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e8d5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_PATH = \"./data/CNN/logs\"\n",
    "CHECKPOINT_PATH = \"./data/CNN/model.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7770c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir $LOG_PATH --host 0.0.0.0 --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e737db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import SampledMNISTData\n",
    "from src.cnn import CNNAutoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483b4507",
   "metadata": {},
   "source": [
    "Zakomentowany kod do uczenia modelu\n",
    "\n",
    "W przypadku chęci modyfikacji, proszę odkomentować kod, przeuczyć model i zapisać go za pomocą metody `save_checkpoint`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e4e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lightning import Trainer\n",
    "# from lightning.pytorch.loggers import TensorBoardLogger\n",
    "# from src.dataset import SampledMNISTData\n",
    "\n",
    "# conv_ae = CNNAutoencoder(latent_dim=2)\n",
    "# trainer = Trainer(\n",
    "#     max_epochs=10, \n",
    "#     logger=TensorBoardLogger(save_dir=LOG_PATH, name=\"conv_ae\", default_hp_metric=False),\n",
    "#     enable_checkpointing=False,\n",
    "#     accelerator=\"auto\",\n",
    "# )\n",
    "# mnist = SampledMNISTData(num_samples_per_class=-1)\n",
    "\n",
    "# trainer.fit(\n",
    "#     model=conv_ae,\n",
    "#     train_dataloaders=mnist,\n",
    "# )\n",
    "\n",
    "# trainer.save_checkpoint(filepath=CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db858da",
   "metadata": {},
   "source": [
    "Wczytujemy przeuczony model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb7b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_ae = CNNAutoencoder.load_from_checkpoint(checkpoint_path=CHECKPOINT_PATH, map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547b5af7",
   "metadata": {},
   "source": [
    "## 2.3. Badanie jakości reprezentacji w zadaniu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ce8c9a",
   "metadata": {},
   "source": [
    "Wczytujemy losową próbkę zbioru danych MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b780bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = SampledMNISTData(num_samples_per_class=100, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9116ecc1",
   "metadata": {},
   "source": [
    "Dla każdej próbki wyciągamy jej reprezentację (wektor dwu-wymiarowy) oraz etykietę:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d59298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import extract_representations\n",
    "\n",
    "\n",
    "representations = extract_representations(\n",
    "    model=cnn_ae,\n",
    "    dataset=mnist,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137c7517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import evaluate_linear    \n",
    "\n",
    "\n",
    "auc_train, auc_test = evaluate_linear(\n",
    "    z_train=representations[\"train\"][\"z\"],\n",
    "    y_train=representations[\"train\"][\"y\"],\n",
    "    z_test=representations[\"test\"][\"z\"],\n",
    "    y_test=representations[\"test\"][\"y\"],\n",
    ")\n",
    "\n",
    "print(f\"AUC => train: {auc_train * 100.0:.2f} [%], test: {auc_test * 100.0:.2f} [%]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be327d5b",
   "metadata": {},
   "source": [
    "## 2.4. Wizualizacja przestrzeni reprezentacji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae906f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from src.utils import visualize_latent_spaces\n",
    "\n",
    "\n",
    "visualize_latent_spaces(representations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b379074f",
   "metadata": {},
   "source": [
    "## 2.5. Wizualizacja jakości rekonstrukcji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566854ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from src.utils import visualize_random_sample\n",
    "\n",
    "    \n",
    "visualize_random_sample(model=cnn_ae, dataset=mnist.mnist_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a07ef0",
   "metadata": {},
   "source": [
    "## 2.6. Odporność modelu na przesunięcia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56306401",
   "metadata": {},
   "source": [
    "## Zadanie 2.1. (0 pkt)\n",
    "Skopiuj implemetację funkcji `shift` z poprzedniego zeszytu do poniższej komórki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad13ae0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4d532e94e36a6121dfe9888543bb06b",
     "grade": true,
     "grade_id": "shift-copy",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def shift(img: torch.Tensor, dx: int, dy: int) -> torch.Tensor:\n",
    "    # TU WPISZ KOD\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26cc03b",
   "metadata": {},
   "source": [
    "Wybieramy dowolną instancję ze zbioru danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233a0312",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = mnist.mnist_train[256]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90404f05",
   "metadata": {},
   "source": [
    "Zbadanie odporności na **przesunięcia poziome**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3095d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "from src.transforms import plot_transformation\n",
    "\n",
    "\n",
    "def shift_horizontally(image: torch.Tensor, dx: int) -> torch.Tensor:\n",
    "    return shift(img=image, dx=dx, dy=0)\n",
    "\n",
    "    \n",
    "plot_transformation(\n",
    "    image=img,\n",
    "    model=cnn_ae,\n",
    "    transformation_fn=shift_horizontally,\n",
    "    keep_channel_dim=True,  # Potrzebne do działania warstw kowolucyjnych\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f78d10b",
   "metadata": {},
   "source": [
    "Zbadanie odporności na **przesunięcia pionowe**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bc2725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_vertically(image: torch.Tensor, dy: int) -> torch.Tensor:\n",
    "    return shift(img=image, dx=0, dy=dy)\n",
    "\n",
    "\n",
    "plot_transformation(\n",
    "    image=img,\n",
    "    model=cnn_ae,\n",
    "    transformation_fn=shift_vertically,\n",
    "    keep_channel_dim=True, # Potrzebne do działania warstw kowolucyjnych\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be32161c",
   "metadata": {},
   "source": [
    "**Obserwacja**: Widzimy, że dla małych wartości przesunięć model działa poprawnie (tzn. rekonstrukcja nadal przypomina tę samą cyfrę). Przy większych przesunięciach rekonstrukcja jest zaburzona, jednak przetransformowana cyfra jest również zbyt zaburzona przez przesunięcie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ee4ea3",
   "metadata": {},
   "source": [
    "## 2.7. Odporność na obroty\n",
    "Inną ważną grupą symetrii w przypadku przetwarzania obrazów jest **grupa obrotów**, np. grupa P4 opisująca obroty obiektów o 90 stopni.\n",
    "\n",
    "Zbadamy teraz jak się zachowuje model oparty o sieci konwolucyjne w przypadku obrotów."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924350a6",
   "metadata": {},
   "source": [
    "## Zadanie 2.2. (2 pkt)\n",
    "Zaimplementuj funkcję `rotate`, która obróci obraz wejściowy `img` o `angle` stopni w lewo względem środka obrazu. Funkcja powinna obsługiwać ujemne wartości parametru obrotu, tzn. `angle < 0` (obrót w prawo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119edff4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e59278b3821b6583efda79ea018d81b6",
     "grade": true,
     "grade_id": "rotate-implementation",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def rotate(img: torch.Tensor, angle: float) -> torch.Tensor:\n",
    "    # TU WPISZ KOD\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d194a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.transforms import plot_transformation\n",
    "\n",
    "\n",
    "plot_transformation(\n",
    "    image=img,\n",
    "    model=cnn_ae,\n",
    "    transformation_fn=rotate,\n",
    "    min_param_value=0,\n",
    "    max_param_value=360,\n",
    "    step=10,\n",
    "    keep_channel_dim=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd767aa",
   "metadata": {},
   "source": [
    "## Zadanie 2.3 (0.5 pkt)\n",
    "Czy autokoder CNN jest odporny na obroty obiektów? Z czego może to wynikać?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb423c73",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9427a5c1c7519ca325c9be6d6148deec",
     "grade": true,
     "grade_id": "cnn-rotate",
     "locked": false,
     "points": 0.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "TU WPISZ ODPOWIEDŹ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
